{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import Image\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from random import randint, uniform\n",
    "from scipy.misc.pilutil import imshow\n",
    "from scipy.misc import imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(label, size):\n",
    "    arr = np.zeros(size)\n",
    "    arr[:, label] = 1\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training sets\n",
    "red_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/train/0/*')\n",
    "yellow_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/train/1/*')\n",
    "green_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/train/2/*')\n",
    "unknown_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/train/3/*')\n",
    "\n",
    "red_features = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in red_filelist])\n",
    "red_labels = one_hot(0, (red_features.shape[0], 4))\n",
    "\n",
    "yellow_features = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in yellow_filelist])\n",
    "yellow_labels = one_hot(1, (yellow_features.shape[0], 4))\n",
    "\n",
    "green_features = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in green_filelist])\n",
    "green_labels = one_hot(2, (green_features.shape[0], 4))\n",
    "\n",
    "unknown_features = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in unknown_filelist])\n",
    "unknown_labels = one_hot(3, (unknown_features.shape[0], 4))\n",
    "\n",
    "features = np.concatenate([red_features, yellow_features, green_features, unknown_features], axis=0)\n",
    "labels = np.concatenate([red_labels, yellow_labels, green_labels, unknown_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test sets\n",
    "# Real Test Images\n",
    "red_tr_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/real/0/*')\n",
    "red_features_tr = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in red_tr_filelist])\n",
    "red_labels_tr = one_hot(0, (red_features_tr.shape[0], 4))\n",
    "\n",
    "yellow_tr_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/real/1/*')\n",
    "yellow_features_tr = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in yellow_tr_filelist])\n",
    "yellow_labels_tr = one_hot(0, (yellow_features_tr.shape[0], 4))\n",
    "\n",
    "green_tr_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/real/2/*')\n",
    "green_features_tr = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in green_tr_filelist])\n",
    "green_labels_tr = one_hot(0, (green_features_tr.shape[0], 4))\n",
    "\n",
    "unknown_tr_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/real/3/*')\n",
    "unknown_features_tr = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in unknown_tr_filelist])\n",
    "unknown_labels_tr = one_hot(0, (unknown_features_tr.shape[0], 4))\n",
    "\n",
    "# Simulated Test Images\n",
    "red_ts_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/sim/0/*')\n",
    "red_features_ts = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in red_ts_filelist])\n",
    "red_labels_ts = one_hot(0, (red_features_ts.shape[0], 4))\n",
    "\n",
    "yellow_ts_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/sim/1/*')\n",
    "yellow_features_ts = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in yellow_ts_filelist])\n",
    "yellow_labels_ts = one_hot(0, (yellow_features_ts.shape[0], 4))\n",
    "\n",
    "green_ts_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/sim/2/*')\n",
    "green_features_ts = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in green_ts_filelist])\n",
    "green_labels_ts = one_hot(0, (green_features_ts.shape[0], 4))\n",
    "\n",
    "unknown_ts_filelist = glob.glob('/home/paperspace/CarND-Capstone/ros/src/tl_detector/tl_classifier_data/test/sim/3/*')\n",
    "unknown_features_ts = np.array([imresize(np.array(Image.open(fname)), (64, 96, 3)) for fname in unknown_ts_filelist])\n",
    "unknown_labels_ts = one_hot(0, (unknown_features_ts.shape[0], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation function\n",
    "def probably_adjust_brightness(img):\n",
    "    gamma = uniform(0.5, 2.0)\n",
    "    inv_gamma = 1. / gamma\n",
    "    lookup_table = np.array([((i / 255.) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(img, lookup_table)\n",
    "\n",
    "def maybe_flip_horizontal(img):\n",
    "    if randint(0, 1) == 0:\n",
    "        return cv2.flip(img, 1)\n",
    "    return img\n",
    "\n",
    "def probably_translate(img):\n",
    "    vertical_shift = randint(-10, 10)\n",
    "    img = np.roll(img, vertical_shift, axis=0)\n",
    "    \n",
    "    horizontal_shift = randint(-10, 10)\n",
    "    img = np.roll(img, horizontal_shift, axis=1)\n",
    "    return img\n",
    "\n",
    "def distort_img(img):\n",
    "    new_img = np.uint8(img.copy())\n",
    "    new_img = probably_translate(new_img)\n",
    "    new_img = probably_adjust_brightness(new_img)\n",
    "    new_img = maybe_flip_horizontal(new_img)\n",
    "    return new_img\n",
    "\n",
    "def get_batch(batch_size, seed_imgs, labels):\n",
    "    num_seed_imgs = seed_imgs.shape[0]\n",
    "    assert batch_size % num_seed_imgs == 0\n",
    "    aug_factor = batch_size / num_seed_imgs\n",
    "    \n",
    "    batch_img = np.empty((batch_size, 64, 96, 3))\n",
    "    batch_label = np.zeros((batch_size, 4))\n",
    "    \n",
    "    batch_index = 0\n",
    "    for i in range(num_seed_imgs):\n",
    "        curr_img = seed_imgs[i]\n",
    "        curr_label = np.argmax(labels[i])\n",
    "        for j in range(aug_factor):\n",
    "            batch_img[batch_index, :] = distort_img(curr_img)\n",
    "            batch_label[batch_index, curr_label] = 1\n",
    "            batch_index += 1\n",
    "            \n",
    "    return batch_img, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class ConvNet:\n",
    "    def __init__(self):\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, 64, 96, 3], name='x')\n",
    "        self.y = tf.placeholder(tf.float32, shape=[None, 4], name='y')\n",
    "        self.phase = tf.placeholder(tf.bool, name='phase')\n",
    "        \n",
    "        # Layers of NN\n",
    "        self.layer1 = self.conv_layer(self.x, 3, 8, self.phase, 'layer1')\n",
    "        self.layer2 = self.conv_layer(self.layer1, 3, 8, self.phase, 'layer2')\n",
    "        self.layer2_pool = tf.nn.max_pool(self.layer2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        self.layer3 = self.conv_layer(self.layer2_pool, 3, 16, self.phase, 'layer3')\n",
    "        self.layer4 = self.conv_layer(self.layer3, 3, 16, self.phase, 'layer4')\n",
    "        self.layer4_pool = tf.nn.max_pool(self.layer4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        self.layer5 = self.conv_layer(self.layer4_pool, 3, 32, self.phase, 'layer5')\n",
    "        self.layer6 = self.conv_layer(self.layer5, 3, 32, self.phase, 'layer6')\n",
    "        self.layer6_pool = tf.nn.max_pool(self.layer6, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        self.debug_shape = tf.shape(self.layer6_pool)\n",
    "        flatten_size = 8 * 12 * 32\n",
    "        self.flatten = tf.reshape(self.layer6_pool, [-1, flatten_size])\n",
    "        self.layer7 = self.fc_layer(self.flatten, 1000, self.phase, 'layer7')\n",
    "        self.layer8 = self.fc_layer(self.layer7, 500, self.phase, 'layer8')\n",
    "        self.layer9 = self.fc_layer(self.layer8, 100, self.phase, 'layer9')\n",
    "        self.logits = tf.contrib.layers.fully_connected(self.layer9, 4, activation_fn=None, scope='logits')\n",
    "        \n",
    "        self.loss = self.setup_loss(self.logits, self.y)\n",
    "        self.accuracy = self.setup_accuracy(self.logits, self.y)\n",
    "        self.inference = tf.argmax(self.logits, 1)\n",
    "        self.train_op = tf.train.AdamOptimizer(1e-4).minimize(self.loss)\n",
    "        \n",
    "    def fc_layer(self, x, hh_size, phase, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            h1 = tf.contrib.layers.fully_connected(x, hh_size, activation_fn=None, scope='fully_connected')\n",
    "            #h2 = tf.contrib.layers.batch_norm(h1, center=True, scale=True, is_training=phase, scope='bn')\n",
    "            return tf.nn.relu(h1, 'relu')\n",
    "        \n",
    "    def conv_layer(self, x, kernel_size, filter_size, phase, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            h1 = tf.contrib.layers.conv2d(x, filter_size, kernel_size, activation_fn=None, scope='convolution')\n",
    "            #h2 = tf.contrib.layers.batch_norm(h1, center=True, scale=True, is_training=phase, scope='bn')\n",
    "            return tf.nn.relu(h1, 'relu')\n",
    "        \n",
    "    def setup_accuracy(self, output, target):\n",
    "        with tf.variable_scope('accuracy'):\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(target, 1), tf.argmax(output, 1)),\n",
    "                                      'float32'))\n",
    "            return accuracy\n",
    "            \n",
    "    def setup_loss(self, output, target):\n",
    "        with tf.variable_scope('loss'):\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=target))\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931744\n",
      "0.566792\n",
      "0.0\n",
      "0.5\n",
      "0.7695\n",
      "0.683521\n",
      "0.0\n",
      "0.9\n",
      "0.381248\n",
      "0.856742\n",
      "0.0\n",
      "1.0\n",
      "0.292285\n",
      "0.883895\n",
      "0.0\n",
      "1.0\n",
      "0.253531\n",
      "0.915106\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    conv_net = ConvNet()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_size = features.shape[0]\n",
    "    max_epoch = 5\n",
    "    for epoch in range(max_epoch):\n",
    "        p = np.random.permutation(features.shape[0])\n",
    "        for i in range(train_size / 4):\n",
    "            s = 4*i\n",
    "            e = s + 4\n",
    "            curr_batch, curr_labels = get_batch(32, features[p[s:e]], labels[p[s:e]])\n",
    "\n",
    "            # Train model with batch\n",
    "            sess.run(conv_net.train_op, feed_dict={\n",
    "                conv_net.x: curr_batch,\n",
    "                conv_net.y: curr_labels,\n",
    "                conv_net.phase: 1\n",
    "            })\n",
    "        print(sess.run(conv_net.loss, feed_dict={\n",
    "            conv_net.x: features,\n",
    "            conv_net.y: labels,\n",
    "            conv_net.phase: 1\n",
    "        }))\n",
    "        print(sess.run(conv_net.accuracy, feed_dict={\n",
    "            conv_net.x: features,\n",
    "            conv_net.y: labels,\n",
    "            conv_net.phase: 1\n",
    "        }))\n",
    "        print(sess.run(conv_net.accuracy, feed_dict={\n",
    "            conv_net.x: red_features_tr,\n",
    "            conv_net.y: red_labels_tr,\n",
    "            conv_net.phase: 1\n",
    "        }))\n",
    "        print(sess.run(conv_net.accuracy, feed_dict={\n",
    "            conv_net.x: red_features_ts,\n",
    "            conv_net.y: red_labels_ts,\n",
    "            conv_net.phase: 1\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
