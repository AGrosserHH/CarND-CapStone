{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# VGG Model based on https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "# Data augmentation based on https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras import backend as K\n",
    "img_dim_ordering = 'tf'\n",
    "K.set_image_dim_ordering(img_dim_ordering)\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = os.path.dirname(os.path.abspath('__file_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping red images\n",
    "def flip(_image):\n",
    "    return cv2.flip(_image,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate images\n",
    "def trans_image(_image,trans_range):    \n",
    "    rows, cols, chan = _image.shape      \n",
    "    tr_x = trans_range#*np.random.uniform()-trans_range/2    \n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,0]])\n",
    "    image_tr = cv2.warpAffine(_image,Trans_M,(cols,rows))    \n",
    "    return image_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brightness\n",
    "def augment_brightness_camera_images(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    image1 = np.array(image1, dtype = np.float64)\n",
    "    random_bright = .5+np.random.uniform()\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1[:,:,2][image1[:,:,2]>255]  = 255\n",
    "    image1 = np.array(image1, dtype = np.uint8)\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shadow\n",
    "def add_random_shadow(image):\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    #random_bright = .25+.7*np.random.uniform()\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    image = cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in(_current,directory, function):\n",
    "    path = os.path.join(_current, directory)\n",
    "    print(path)\n",
    "    image_list_ = []\n",
    "    for filename in glob.glob(path+'/*.png'): \n",
    "        im=Image.open(filename).convert('RGB')    \n",
    "        if function == 'flip':\n",
    "            im = flip(np.array(im))\n",
    "        elif function == 'trans':\n",
    "            im = trans_image(np.array(im),20)\n",
    "        elif function == 'bright':        \n",
    "            im = augment_brightness_camera_images(np.array(im))\n",
    "        elif function == 'shadow':\n",
    "            add_random_shadow(np.array(im))\n",
    "        else:\n",
    "            im = im            \n",
    "        opencvImage = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2BGR)    \n",
    "        new_width  = 224\n",
    "        new_height = 224\n",
    "        im = cv2.resize(opencvImage, (224, 224),interpolation = cv2.INTER_CUBIC).astype(np.float32)\n",
    "        im[:,:,0] -= 103.939\n",
    "        im[:,:,1] -= 116.779\n",
    "        im[:,:,2] -= 123.68\n",
    "            #im = im.transpose((2,0,1))    \n",
    "            #im = cv2.resize(opencvImage,(new_width, new_height), interpolation = cv2.INTER_CUBIC)    \n",
    "        image_list_.append(im)\n",
    "    print(len(image_list_))\n",
    "    return image_list_ \n",
    "\n",
    "#image_list_red = read_in(current, '_0_','shadow')\n",
    "#print(len(image_list_red))\n",
    "#imshow(image_list_red[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\tensorflow-vgg\\_0_\n",
      "1598\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_0_\n",
      "1598\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_0_\n",
      "1598\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_0_\n",
      "1598\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_0_\n",
      "1598\n",
      "7990\n",
      "7990\n"
     ]
    }
   ],
   "source": [
    "image_list_red_norm = read_in(current, '_0_','')\n",
    "image_list_red_flip = read_in(current, '_0_','flip')\n",
    "image_list_red_trans = read_in(current, '_0_','trans')\n",
    "image_list_red_bright = read_in(current, '_0_','bright')\n",
    "image_list_red_shadow = read_in(current, '_0_','shadow')\n",
    "\n",
    "val_red = np.concatenate([image_list_red_norm, image_list_red_flip,image_list_red_trans,image_list_red_bright,image_list_red_shadow])\n",
    "print(len(val_red))\n",
    "lab_red = np.zeros(len(val_red))\n",
    "print(len(lab_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\tensorflow-vgg\\_1_\n",
      "285\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_1_\n",
      "285\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_1_\n",
      "285\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_1_\n",
      "285\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_1_\n",
      "285\n",
      "1425\n",
      "1425\n"
     ]
    }
   ],
   "source": [
    "image_list_yellow_norm = read_in(current, '_1_','')\n",
    "image_list_yellow_flip = read_in(current, '_1_','flip')\n",
    "image_list_yellow_trans = read_in(current, '_1_','trans')\n",
    "image_list_yellow_bright = read_in(current, '_1_','bright')\n",
    "image_list_yellow_shadow = read_in(current, '_1_','shadow')\n",
    "\n",
    "val_yellow = np.concatenate([image_list_yellow_norm, image_list_yellow_flip,image_list_yellow_trans,image_list_yellow_bright,image_list_yellow_shadow])\n",
    "print(len(val_yellow))\n",
    "lab_yellow = np.ones(len(val_yellow))\n",
    "print(len(lab_yellow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Programming\\Python\\tensorflow-vgg\\_2_\n",
      "1223\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_2_\n",
      "1223\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_2_\n",
      "1223\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_2_\n",
      "1223\n",
      "D:\\Programming\\Python\\tensorflow-vgg\\_2_\n",
      "1223\n"
     ]
    }
   ],
   "source": [
    "image_list_green_norm = read_in(current, '_2_','')\n",
    "image_list_green_flip = read_in(current, '_2_','flip')\n",
    "image_list_green_trans = read_in(current, '_2_','trans')\n",
    "image_list_green_bright = read_in(current, '_2_','bright')\n",
    "image_list_green_shadow = read_in(current, '_2_','shadow')\n",
    "\n",
    "val_green = np.concatenate([image_list_green_norm, image_list_green_flip,image_list_green_trans,image_list_green_bright,image_list_green_shadow])\n",
    "print(len(val_green))\n",
    "lab_green = np.empty(len(val_green))\n",
    "lab_green.fill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_none_norm = read_in(current, '_4_','')\n",
    "image_list_none_flip = read_in(current, '_4_','flip')\n",
    "image_list_none_trans = read_in(current, '_4_','trans')\n",
    "image_list_none_bright = read_in(current, '_4_','bright')\n",
    "image_list_none_shadow = read_in(current, '_4_','shadow')\n",
    "\n",
    "val_none = np.concatenate([image_list_none_norm, image_list_none_flip,image_list_none_trans,image_list_none_bright,image_list_none_shadow])\n",
    "print(len(val_none))\n",
    "lab_none = np.empty(len(val_none))\n",
    "lab_none.fill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tot = np.concatenate([val_red,val_yellow,val_green,val_none])                         \n",
    "lab_tot = np.concatenate([lab_red , lab_yellow, lab_green, lab_none])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "def pretrained_model(img_shape, num_classes, layer_type):\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "    #model_vgg16_conv.summary()\n",
    "    for layer in model_vgg16_conv.layers:        \n",
    "        layer.trainable = False\n",
    "    \n",
    "    #Create your own input format\n",
    "    keras_input = Input(shape=img_shape, name = 'image_input')\n",
    "    \n",
    "    #Use the generated model \n",
    "    output_vgg16_conv = model_vgg16_conv(keras_input)\n",
    "    \n",
    "    #Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(4096, activation=layer_type, name='fc1')(x)\n",
    "    x = Dense(400, activation=layer_type, name='fc2')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #Create your own model \n",
    "    pretrained_model = Model(input=keras_input, output=x)\n",
    "    pretrained_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(val_tot, lab_tot, test_size=0.33, random_state=42, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "model = pretrained_model(x_train.shape[1:], len(set(y_train)), 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size = 1000, nb_epoch= 20, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
